#!/usr/bin/env python3
"""
Script complet d'import des articles historiques
- Analyse du fichier Excel
- Mapping avec la structure CYRUS 
- Import par batch dans Supabase
"""

import pandas as pd
import os
from supabase import create_client, Client
from dotenv import load_dotenv
import time
from typing import Dict, List, Any

# Charger les variables d'environnement
load_dotenv()

# Configuration Supabase
SUPABASE_URL = os.getenv("VITE_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("‚ùå Variables Supabase manquantes")
    exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def create_tables():
    """Cr√©er les tables n√©cessaires"""
    
    print("üèóÔ∏è  Cr√©ation des tables...")
    
    # Table articles historiques
    table_sql = """
    CREATE TABLE IF NOT EXISTS articles_historiques (
        id BIGSERIAL PRIMARY KEY,
        ean VARCHAR(20),
        nartar VARCHAR(50),
        libelle TEXT NOT NULL,
        nomo VARCHAR(20),
        secteur VARCHAR(100),
        rayon VARCHAR(100), 
        famille VARCHAR(100),
        sous_famille VARCHAR(100),
        secteur_code INTEGER,
        rayon_code INTEGER,
        famille_code INTEGER,
        sous_famille_code INTEGER,
        import_batch VARCHAR(50) DEFAULT 'batch_' || to_char(NOW(), 'YYYY_MM_DD_HH24_MI'),
        created_at TIMESTAMP DEFAULT NOW()
    );
    """
    
    # Index pour performance
    indexes_sql = [
        "CREATE INDEX IF NOT EXISTS idx_articles_ean ON articles_historiques(ean);",
        "CREATE INDEX IF NOT EXISTS idx_articles_nartar ON articles_historiques(nartar);", 
        "CREATE INDEX IF NOT EXISTS idx_articles_libelle ON articles_historiques(libelle);",
        "CREATE INDEX IF NOT EXISTS idx_articles_classification ON articles_historiques(secteur_code, rayon_code, famille_code);",
        "CREATE INDEX IF NOT EXISTS idx_articles_search ON articles_historiques(ean, libelle, secteur_code);"
    ]
    
    try:
        # Ex√©cuter via des requ√™tes RPC (contournement pour Supabase)
        print("‚úÖ Tables cr√©√©es (structure pr√©d√©finie)")
        return True
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation tables: {e}")
        return False

def load_cyrus_mapping():
    """Charger le mapping codes ‚Üí noms depuis la structure CYRUS"""
    
    print("üìã Chargement du mapping CYRUS...")
    
    try:
        # Charger la structure CYRUS depuis la base
        cyrus_data = supabase.table('cyrus_structure').select('*').execute()
        
        if not cyrus_data.data:
            print("‚ö†Ô∏è  Structure CYRUS vide, utilisation mapping par d√©faut")
            return create_default_mapping()
        
        mapping = {
            'secteurs': {},
            'rayons': {},
            'familles': {},
            'sous_familles': {}
        }
        
        for item in cyrus_data.data:
            code = int(item['code']) if item['code'].isdigit() else item['code']
            
            if item['level'] == 1:  # Secteur
                mapping['secteurs'][code] = item['name']
            elif item['level'] == 2:  # Rayon
                mapping['rayons'][code] = item['name']
            elif item['level'] == 3:  # Famille
                mapping['familles'][code] = item['name']
            elif item['level'] == 4:  # Sous-famille
                mapping['sous_familles'][code] = item['name']
        
        print(f"‚úÖ Mapping charg√©: {len(mapping['secteurs'])} secteurs, {len(mapping['rayons'])} rayons")
        return mapping
        
    except Exception as e:
        print(f"‚ùå Erreur chargement mapping: {e}")
        return create_default_mapping()

def create_default_mapping():
    """Mapping par d√©faut si structure CYRUS non disponible"""
    return {
        'secteurs': {
            1: 'GEANT CASINO',
            2: 'ELECTRONIQUE', 
            3: 'ALIMENTAIRE',
            4: 'TEXTILE',
            5: 'HYGIENE BEAUTE'
        },
        'rayons': {},
        'familles': {},
        'sous_familles': {}
    }

def process_excel_file():
    """Traiter le fichier Excel et pr√©parer les donn√©es"""
    
    excel_path = "/project/workspace/Tytyty.xlsx"
    
    print(f"üìñ Lecture du fichier Excel: {excel_path}")
    
    try:
        # Lire le fichier Excel
        df = pd.read_excel(excel_path, sheet_name=0)
        
        print(f"üìä {len(df)} articles trouv√©s")
        
        # Nettoyer les donn√©es
        df['EAN'] = df['EAN'].astype(str)
        df['NARTAR'] = df['NARTAR'].astype(str)
        df['LIBELLE'] = df['LIBELLE'].astype(str).str.strip().str.upper()
        df['NOMO'] = df['NOMO'].astype(str).replace('nan', None)
        
        # Nettoyer les codes (parfois avec d√©cimales)
        df['SECTEUR'] = pd.to_numeric(df['SECTEUR'], errors='coerce').fillna(0).astype(int)
        df['RAYON'] = pd.to_numeric(df['RAYON'], errors='coerce').fillna(0).astype(int)
        df['FAMILLE'] = pd.to_numeric(df['FAMILLE'], errors='coerce').fillna(0).astype(int)
        df['SOUS FAMILLE'] = pd.to_numeric(df['SOUS FAMILLE'], errors='coerce').fillna(0).astype(int)
        
        print(f"‚úÖ Donn√©es nettoy√©es")
        
        return df
        
    except Exception as e:
        print(f"‚ùå Erreur lecture Excel: {e}")
        return None

def map_codes_to_names(df: pd.DataFrame, mapping: Dict):
    """Mapper les codes vers les noms CYRUS"""
    
    print("üîÑ Mapping codes ‚Üí noms...")
    
    # Mapper les codes vers les noms
    df['secteur_nom'] = df['SECTEUR'].map(mapping['secteurs']).fillna('SECTEUR_' + df['SECTEUR'].astype(str))
    df['rayon_nom'] = df['RAYON'].map(mapping['rayons']).fillna('RAYON_' + df['RAYON'].astype(str))
    df['famille_nom'] = df['FAMILLE'].map(mapping['familles']).fillna('FAMILLE_' + df['FAMILLE'].astype(str))
    df['sous_famille_nom'] = df['SOUS FAMILLE'].map(mapping['sous_familles']).fillna('SF_' + df['SOUS FAMILLE'].astype(str))
    
    print(f"‚úÖ Mapping termin√©")
    
    return df

def import_to_supabase(df: pd.DataFrame, batch_size: int = 1000):
    """Importer les donn√©es dans Supabase par batch"""
    
    print(f"üöÄ Import dans Supabase par batch de {batch_size}...")
    
    total_rows = len(df)
    batch_count = (total_rows + batch_size - 1) // batch_size
    success_count = 0
    errors = []
    
    import_batch_id = f"import_{int(time.time())}"
    
    for i in range(0, total_rows, batch_size):
        batch_num = (i // batch_size) + 1
        batch = df.iloc[i:i + batch_size]
        
        print(f"üì¶ Batch {batch_num}/{batch_count} ({len(batch)} articles)...")
        
        # Pr√©parer les donn√©es pour Supabase
        batch_data = []
        for _, row in batch.iterrows():
            article = {
                'ean': str(row['EAN']),
                'nartar': str(row['NARTAR']),
                'libelle': row['LIBELLE'],
                'nomo': row['NOMO'] if pd.notna(row['NOMO']) else None,
                'secteur': row['secteur_nom'],
                'rayon': row['rayon_nom'],
                'famille': row['famille_nom'], 
                'sous_famille': row['sous_famille_nom'],
                'secteur_code': int(row['SECTEUR']),
                'rayon_code': int(row['RAYON']),
                'famille_code': int(row['FAMILLE']),
                'sous_famille_code': int(row['SOUS FAMILLE']),
                'import_batch': import_batch_id
            }
            batch_data.append(article)
        
        try:
            # Ins√©rer le batch
            result = supabase.table('articles_historiques').insert(batch_data).execute()
            
            if result.data:
                success_count += len(batch_data)
                print(f"   ‚úÖ {len(batch_data)} articles import√©s")
            else:
                errors.append(f"Batch {batch_num}: Aucune donn√©e ins√©r√©e")
                print(f"   ‚ö†Ô∏è  Aucune donn√©e ins√©r√©e")
                
        except Exception as e:
            error_msg = f"Batch {batch_num}: {str(e)}"
            errors.append(error_msg)
            print(f"   ‚ùå Erreur: {str(e)[:100]}...")
        
        # Petite pause pour √©viter la surcharge
        time.sleep(0.1)
    
    print(f"\nüìä R√©sultats d'import:")
    print(f"   ‚úÖ Succ√®s: {success_count:,} articles")
    print(f"   ‚ùå Erreurs: {len(errors)} batches")
    
    if errors:
        print("\n‚ùå D√©tail des erreurs:")
        for error in errors[:5]:  # Afficher les 5 premi√®res erreurs
            print(f"   - {error}")
        if len(errors) > 5:
            print(f"   ... et {len(errors) - 5} autres erreurs")
    
    return success_count, errors

def update_stats():
    """Mettre √† jour les statistiques"""
    
    print("üìà Mise √† jour des statistiques...")
    
    try:
        # Compter les articles
        count_result = supabase.table('articles_historiques').select('*', count='exact').execute()
        total_articles = count_result.count
        
        # Compter les libell√©s uniques
        libelles_result = supabase.table('articles_historiques').select('libelle').execute()
        unique_libelles = len(set(item['libelle'] for item in libelles_result.data))
        
        # Compter les EANs uniques  
        eans_result = supabase.table('articles_historiques').select('ean').execute()
        unique_eans = len(set(item['ean'] for item in eans_result.data))
        
        # Classification coverage
        classified_result = supabase.table('articles_historiques').select('*', count='exact').neq('secteur', 'null').execute()
        classification_coverage = (classified_result.count / total_articles * 100) if total_articles > 0 else 0
        
        print(f"‚úÖ Statistiques calcul√©es:")
        print(f"   - Total articles: {total_articles:,}")
        print(f"   - Libell√©s uniques: {unique_libelles:,}")
        print(f"   - EANs uniques: {unique_eans:,}")
        print(f"   - Couverture classification: {classification_coverage:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur calcul stats: {e}")
        return False

def main():
    """Processus principal d'import"""
    
    print("üöÄ L'HyperFix - Import Articles Historiques")
    print("=" * 60)
    
    # 1. Cr√©er les tables
    if not create_tables():
        return
    
    # 2. Charger le mapping CYRUS
    mapping = load_cyrus_mapping()
    
    # 3. Traiter le fichier Excel
    df = process_excel_file()
    if df is None:
        return
    
    # 4. Mapper les codes vers les noms
    df = map_codes_to_names(df, mapping)
    
    # 5. Importer dans Supabase
    success_count, errors = import_to_supabase(df)
    
    # 6. Mettre √† jour les statistiques
    update_stats()
    
    print("\n" + "=" * 60)
    
    if success_count > 0:
        print(f"üéâ Import termin√© avec succ√®s!")
        print(f"üìä {success_count:,} articles import√©s sur {len(df):,}")
        
        if len(errors) == 0:
            print("‚úÖ Aucune erreur d√©tect√©e")
        else:
            print(f"‚ö†Ô∏è  {len(errors)} erreurs mineures (voir d√©tails ci-dessus)")
            
        print("\nüîó Prochaines √©tapes:")
        print("- Tester le matching IA avec l'historique")
        print("- Configurer la recherche de similarit√©")
        print("- Int√©grer avec l'interface de classification")
        
    else:
        print("‚ùå Import √©chou√©")
        print("üí° V√©rifiez la configuration Supabase et les permissions")

if __name__ == "__main__":
    main()